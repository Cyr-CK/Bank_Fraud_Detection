{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'  \n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Pour les pipelines imblearn\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_parquet(\"../preprocessed_train_data.parquet\")\n",
    "test_df = pd.read_parquet(\"../preprocessed_test_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"FlagImpaye\"])\n",
    "y_train = train_df[\"FlagImpaye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(columns=[\"FlagImpaye\"])\n",
    "y_test = test_df[\"FlagImpaye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(method):\n",
    "    \"\"\"\n",
    "    Fabrique une pipeline selon la méthode de sampling.\n",
    "    'clf' sera le RandomForest. \n",
    "    \"\"\"\n",
    "    if method == \"Undersampled\":\n",
    "        pipe = ImbPipeline([\n",
    "            ('under', RandomUnderSampler(random_state=42)),\n",
    "            ('clf', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "\n",
    "    elif method == \"Oversampled (SMOTE)\":\n",
    "        pipe = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('clf', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        \n",
    "    elif method == \"Oversampled (ADASYN)\":\n",
    "        pipe = ImbPipeline([\n",
    "            ('adasyn', ADASYN(random_state=42)),\n",
    "            ('clf', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        \n",
    "    elif method == \"Hybrid (SMOTE+Tomek)\":\n",
    "        pipe = ImbPipeline([\n",
    "            ('smote_tomek', SMOTETomek(random_state=42)),\n",
    "            ('clf', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f\"Méthode {method} inconnue.\")\n",
    "        \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des approches qu'on veut tester\n",
    "methods = [\n",
    "    \"Undersampled\",\n",
    "    \"Oversampled (SMOTE)\",\n",
    "    \"Oversampled (ADASYN)\",\n",
    "    \"Hybrid (SMOTE+Tomek)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définir un param_grid pour chaque pipeline\n",
    "\n",
    "param_grids = {\n",
    "\n",
    "    \"Undersampled\": {\n",
    "        'under__sampling_strategy': [0.5, 1.0],  \n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__max_depth': [10, 20],\n",
    "    },\n",
    "    \n",
    "    \"Oversampled (SMOTE)\": {\n",
    "        'smote__sampling_strategy': [0.5, 1.0],\n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__max_depth': [10, 20],\n",
    "    },\n",
    "    \n",
    "    \"Oversampled (ADASYN)\": {\n",
    "        'adasyn__sampling_strategy': [0.5, 1.0],\n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__max_depth': [10, 20],\n",
    "    },\n",
    "    \n",
    "    \"Hybrid (SMOTE+Tomek)\": {\n",
    "        'smote_tomek__sampling_strategy': [0.5, 1.0],\n",
    "        'clf__n_estimators': [50, 100],\n",
    "        'clf__max_depth': [10, 20],\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Boucler sur chaque pipeline + gridsearch\n",
    "\n",
    "def run_all_pipelines_with_gridsearch(X, y):\n",
    "    \"\"\"\n",
    "    Cette fonction boucle sur chaque methode de sampling,\n",
    "    lance un GridSearchCV pour trouver la meilleure combo\n",
    "    d'hyperparametres. On retient la F1-score comme scoring.\n",
    "    Renvoie un DataFrame avec un résumé des résultats.\n",
    "    \"\"\"\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scoring = {\n",
    "    'f1': 'f1',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'pr_auc': 'average_precision'\n",
    "}\n",
    "    # On stocke les resultats\n",
    "    results_list = []\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\n=== Méthode: {method} ===\")\n",
    "        \n",
    "        pipeline = make_pipeline(method)\n",
    "        param_grid = param_grids[method]\n",
    "        \n",
    "        # On utilise la F1 comme métrique principale\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=pipeline,\n",
    "            param_grid=param_grid,\n",
    "            scoring=scoring,     \n",
    "            cv=cv,\n",
    "             refit='f1',\n",
    "            n_jobs=12,        \n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X, y)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        best_f1 = grid_search.best_score_\n",
    "        best_params = grid_search.best_params_\n",
    "        exec_time = end_time - start_time\n",
    "        \n",
    "        print(f\"Meilleure F1 trouvée: {best_f1:.4f}\")\n",
    "        print(f\"Meilleurs paramètres: {best_params}\")\n",
    "        print(f\"Temps d'execution: {exec_time:.2f}s\")\n",
    "        \n",
    "        results_list.append({\n",
    "            'Method': method,\n",
    "            'Best F1': best_f1,\n",
    "            'Best Params': best_params,\n",
    "            'Execution Time (s)': exec_time\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Méthode: Undersampled ===\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Meilleure F1 trouvée: 0.0866\n",
      "Meilleurs paramètres: {'clf__max_depth': 20, 'clf__n_estimators': 100, 'under__sampling_strategy': 0.5}\n",
      "Temps d'execution: 192.53s\n",
      "\n",
      "=== Méthode: Oversampled (SMOTE) ===\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Meilleure F1 trouvée: 0.1685\n",
      "Meilleurs paramètres: {'clf__max_depth': 20, 'clf__n_estimators': 100, 'smote__sampling_strategy': 0.5}\n",
      "Temps d'execution: 20022.63s\n",
      "\n",
      "=== Méthode: Oversampled (ADASYN) ===\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Meilleure F1 trouvée: 0.1684\n",
      "Meilleurs paramètres: {'adasyn__sampling_strategy': 0.5, 'clf__max_depth': 20, 'clf__n_estimators': 100}\n",
      "Temps d'execution: 17652.11s\n",
      "\n",
      "=== Méthode: Hybrid (SMOTE+Tomek) ===\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Meilleure F1 trouvée: 0.1685\n",
      "Meilleurs paramètres: {'clf__max_depth': 20, 'clf__n_estimators': 100, 'smote_tomek__sampling_strategy': 0.5}\n",
      "Temps d'execution: 21313.25s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Best F1</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undersampled</td>\n",
       "      <td>0.086578</td>\n",
       "      <td>{'clf__max_depth': 20, 'clf__n_estimators': 10...</td>\n",
       "      <td>192.532778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oversampled (SMOTE)</td>\n",
       "      <td>0.168499</td>\n",
       "      <td>{'clf__max_depth': 20, 'clf__n_estimators': 10...</td>\n",
       "      <td>20022.630821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oversampled (ADASYN)</td>\n",
       "      <td>0.168384</td>\n",
       "      <td>{'adasyn__sampling_strategy': 0.5, 'clf__max_d...</td>\n",
       "      <td>17652.105721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hybrid (SMOTE+Tomek)</td>\n",
       "      <td>0.168500</td>\n",
       "      <td>{'clf__max_depth': 20, 'clf__n_estimators': 10...</td>\n",
       "      <td>21313.250225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Method   Best F1  \\\n",
       "0          Undersampled  0.086578   \n",
       "1   Oversampled (SMOTE)  0.168499   \n",
       "2  Oversampled (ADASYN)  0.168384   \n",
       "3  Hybrid (SMOTE+Tomek)  0.168500   \n",
       "\n",
       "                                         Best Params  Execution Time (s)  \n",
       "0  {'clf__max_depth': 20, 'clf__n_estimators': 10...          192.532778  \n",
       "1  {'clf__max_depth': 20, 'clf__n_estimators': 10...        20022.630821  \n",
       "2  {'adasyn__sampling_strategy': 0.5, 'clf__max_d...        17652.105721  \n",
       "3  {'clf__max_depth': 20, 'clf__n_estimators': 10...        21313.250225  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = run_all_pipelines_with_gridsearch(X_train, y_train)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meilleure méthode: Hybrid (SMOTE+Tomek)\n",
      "Meilleure F1 en cross-val: 0.1685\n",
      "Meilleurs paramètres: {'clf__max_depth': 20, 'clf__n_estimators': 100, 'smote_tomek__sampling_strategy': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#On cherche la ligne qui a la F1 la plus elevée\n",
    "best_idx = results_df['Best F1'].idxmax()\n",
    "best_method = results_df.loc[best_idx, 'Method']\n",
    "best_f1_score = results_df.loc[best_idx, 'Best F1']\n",
    "best_params = results_df.loc[best_idx, 'Best Params']\n",
    "\n",
    "print(f\"\\nMeilleure méthode: {best_method}\")\n",
    "print(f\"Meilleure F1 en cross-val: {best_f1_score:.4f}\")\n",
    "print(f\"Meilleurs paramètres: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Barplot for F1 Scores\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m sns\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest F1\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMethod\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[43mresults_df\u001b[49m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 Score Comparison by Sampling Method\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Barplot for F1 Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Best F1', y='Method', data=results_df, palette='viridis')\n",
    "plt.title('F1 Score Comparison by Sampling Method')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank_fraud_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
